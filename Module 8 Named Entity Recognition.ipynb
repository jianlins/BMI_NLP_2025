{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JcZOhxh0Rn4"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jianlins/BMI_NLP_2025/blob/main/Module%208%20Named%20Entity%20Recognition.ipynb)\n",
    "\n",
    "# Named Entity Recognition\n",
    "\n",
    "We will continue use this [UUDeCART](https://github.com/UUDeCART/decart_rule_based_nlp) dataset. Instead of converting the labels into sentence labels, we will keep original concept labels and convert them into [BIO format](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)). Then your excerice will take from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eL5y70aI1W-j"
   },
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-bUiTxtqluj"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://github.com/UUDeCART/decart_rule_based_nlp/raw/master/data/training_v2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Efix7RESqo7S"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://github.com/UUDeCART/decart_rule_based_nlp/raw/master/data/test_v2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1708683687928,
     "user": {
      "displayName": "Jade Broken",
      "userId": "16103365057160619176"
     },
     "user_tz": 420
    },
    "id": "OPNQmUpmqtrq",
    "outputId": "21de9404-50f2-4549-cfee-47c5879a2c30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data  test_v2.zip  training_v2.zip\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TFVFTfI_qvxp"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!unzip training_v2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yUc-FWcPqwi6"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!unzip test_v2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1708683688347,
     "user": {
      "displayName": "Jade Broken",
      "userId": "16103365057160619176"
     },
     "user_tz": 420
    },
    "id": "p0daHJoaq4MD",
    "outputId": "c6a2e7a9-f25d-4e60-b446-2db6e29829bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data  test_v2  test_v2.zip  training_v2\ttraining_v2.zip\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1FzWMzA1c1j"
   },
   "source": [
    "## Install & import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ONbAsYwBq9bP"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install quicksectx git+https://github.com/medspacy/medspacy_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bOTovA88rIrq"
   },
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "from medspacy_io.reader import BratDocReader\n",
    "from medspacy_io.reader import BratDirReader\n",
    "import spacy\n",
    "from pathlib import Path\n",
    "from medspacy_io.vectorizer import Vectorizer\n",
    "from spacy.tokens import Doc\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gGKInWvJrUPh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 135,
     "status": "ok",
     "timestamp": 1708683813021,
     "user": {
      "displayName": "Jade Broken",
      "userId": "16103365057160619176"
     },
     "user_tz": 420
    },
    "id": "nx6cwF9ZsQaq",
    "outputId": "583fcfe3-a862-4ba9-ec42-d957dfac5579"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dataset files does not include schema configuration, let's create one\n",
    "concepts=['EVIDENCE_OF_PNEUMONIA', 'PNEUMONIA_DOC_NO', 'PNEUMONIA_DOC_YES']\n",
    "lines=['[entities]']+concepts\n",
    "Path('annotation.conf').write_text('\\n'.join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uNUKfJjGgy41"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lou0UIMDgzwQ"
   },
   "source": [
    "## Now read the data as spaCy Doc objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdi6uXEWrwxn"
   },
   "outputs": [],
   "source": [
    "# set up the Brat reader\n",
    "nlp=spacy.load(\"en_core_web_sm\", disable=['ner'])\n",
    "dir_reader = BratDirReader(nlp=nlp, support_overlap=True, recursive=True, schema_file='annotation.conf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-QzGXRqJ3UoV"
   },
   "outputs": [],
   "source": [
    "train_docs = dir_reader.read(txt_dir='training_v2')\n",
    "test_docs = dir_reader.read(txt_dir='training_v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFQwtegloT8a"
   },
   "source": [
    "## Convert to BIO\n",
    "\n",
    "I've provided the function for the conversion to save your time. Now the output string would be the same as the book is using. You can take the ouput string to train your NER models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-8Vju9r93a-u"
   },
   "outputs": [],
   "source": [
    "def spans_to_bio(doc:Doc, anno_types:List[str], abbr:bool=True)->str:\n",
    "  \"\"\"\n",
    "  Converts spans in a spaCy Doc object to a BIO-formatted string, with an option\n",
    "  to abbreviate the entity labels. It adds an empty line between sentences to improve\n",
    "  readability.\n",
    "\n",
    "  Parameters:\n",
    "  - doc (Doc): The spaCy Doc object containing the text and its annotations, including\n",
    "                entities and sentence boundaries.\n",
    "  - anno_types (List[str]): A list of annotation types to include in the output. These\n",
    "                            types should correspond to the keys in `doc.spans`.\n",
    "  - abbr (bool, optional): If True, entity labels are abbreviated to their initials.\n",
    "                            Defaults to True.\n",
    "\n",
    "  Returns:\n",
    "  - str: A string where each token is followed by its BIO tag (with the entity label if applicable),\n",
    "          formatted as \"token B-entity\" or \"token I-entity\" for tokens within entities, and\n",
    "          \"token O\" for tokens outside any entities. Sentences are separated by an empty line.\n",
    "  \"\"\"\n",
    "  # Initialize a dictionary to hold BIO tags for each token index\n",
    "  bio_tags = {token.i: 'O' for token in doc}  # Default to 'O' for outside any entity\n",
    "\n",
    "  # Preprocess spans to assign BIO tags\n",
    "  for anno_type in anno_types:\n",
    "    for span in doc.spans.get(anno_type, []):\n",
    "      if span:  # Check if span is not empty\n",
    "        label=span.label_\n",
    "        if abbr:\n",
    "          label=''.join([w[0] for w in label.split('_')])\n",
    "        bio_tags[span.start] = f\"B-{label}\"  # Begin tag for the first token in the span\n",
    "        for token in span[1:]:  # Inside tags for the rest of the tokens in the span\n",
    "          bio_tags[token.i] = f\"I-{label}\"\n",
    "\n",
    "  # Generate BIO format string\n",
    "  bio_text = []\n",
    "  for sent in doc.sents:\n",
    "    for i,token in enumerate(sent):\n",
    "      # trim the whitespaces on both sides of a sentence\n",
    "      if (i==0 or i==len(sent)-1) and str(token).strip()=='':\n",
    "        bio_text.append('')\n",
    "      elif str(token).strip()=='':\n",
    "        # clean up extra whitespaces within a sentence.\n",
    "        bio_text.append(f' \\t{bio_tags[token.i]}')\n",
    "      else:\n",
    "        bio_text.append(f\"{token.text} {bio_tags[token.i]}\")\n",
    "    bio_text.append('')  # Empty line between sentences\n",
    "  return '\\n'.join(bio_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MosNew19kfZP"
   },
   "outputs": [],
   "source": [
    "bio_str=spans_to_bio(train_docs[0], ['EVIDENCE_OF_PNEUMONIA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 140,
     "status": "ok",
     "timestamp": 1708686119140,
     "user": {
      "displayName": "Jade Broken",
      "userId": "16103365057160619176"
     },
     "user_tz": 420
    },
    "id": "NRn0H1L-nTrP",
    "outputId": "2e2b4ecc-6600-4c4d-dcbb-89a0be2fb677"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "A B-EOP\n",
      "right I-EOP\n",
      "IJ I-EOP\n",
      "line I-EOP\n",
      ", I-EOP\n",
      "NGT I-EOP\n",
      ", I-EOP\n",
      "and I-EOP\n",
      "ETT I-EOP\n",
      "are I-EOP\n",
      " \tI-EOP\n",
      "unchanged I-EOP\n",
      "as I-EOP\n",
      "are I-EOP\n",
      "the I-EOP\n",
      "parenchymal I-EOP\n",
      "changes I-EOP\n",
      "in I-EOP\n",
      "the I-EOP\n",
      "lungs I-EOP\n",
      "compared O\n",
      "to O\n",
      "the O\n",
      "earlier O\n",
      " \tO\n",
      "chest O\n",
      "x O\n",
      "- O\n",
      "ray O\n",
      "this O\n",
      "morning O\n"
     ]
    }
   ],
   "source": [
    "# Here just show an example that contains an EVIDENCE_OF_PNEUMONIA annotation\n",
    "print(bio_str[1516:1805])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODeQF_F8oqP_"
   },
   "source": [
    "## Here is your solution for NER.\n",
    "Now your task is to implement an NER solution and evaluate it. Please refer to Chapter 5 for detailed guidance. It's important to note that the chapter provides only the key functions necessary for implementing the solution. You will need to comprehend how these functions operate in order to successfully integrate them into your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ct-OLiBTnj1e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
