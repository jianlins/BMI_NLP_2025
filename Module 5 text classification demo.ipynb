{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JcZOhxh0Rn4"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jianlins/BMI_NLP_2025/blob/main/Module%205%20text%20classification%20demo.ipynb)\n",
    "\n",
    "# Sentence classification\n",
    "\n",
    "We will use previous [UUDeCART](https://github.com/UUDeCART/decart_rule_based_nlp) dataset. This dataset was created using the MIMIC demo dataset and was labeled by Dr. Barbara E. Jones. It is relatively small and was not annotated by a second annotator. Therefore, it should only be used for learning or demonstration purposes.\n",
    "\n",
    "We will start from a very simple implementation, just to get you familiar with a ML model training and evaluation process. And then you will try some extra exercises to see how you can make the baseline better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eL5y70aI1W-j"
   },
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-bUiTxtqluj"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/UUDeCART/decart_rule_based_nlp/raw/master/data/training_v2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Efix7RESqo7S"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/UUDeCART/decart_rule_based_nlp/raw/master/data/test_v2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 151,
     "status": "ok",
     "timestamp": 1706807722002,
     "user": {
      "displayName": "Jade Broken",
      "userId": "16103365057160619176"
     },
     "user_tz": 420
    },
    "id": "OPNQmUpmqtrq",
    "outputId": "d7a9023b-5ac7-429b-90f7-2a40d284ac13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data  test_v2.zip  training_v2.zip\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1706807766485,
     "user": {
      "displayName": "Jade Broken",
      "userId": "16103365057160619176"
     },
     "user_tz": 420
    },
    "id": "TFVFTfI_qvxp",
    "outputId": "f4beb296-c109-41fa-f98a-6715404d0145"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  training_v2.zip\n",
      "caution: filename not matched:  test_v2.zip\n"
     ]
    }
   ],
   "source": [
    "!unzip training_v2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yUc-FWcPqwi6"
   },
   "outputs": [],
   "source": [
    "!unzip test_v2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 158,
     "status": "ok",
     "timestamp": 1706807777517,
     "user": {
      "displayName": "Jade Broken",
      "userId": "16103365057160619176"
     },
     "user_tz": 420
    },
    "id": "p0daHJoaq4MD",
    "outputId": "dab65fd4-950a-40e4-a8cc-2332aab440e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data  test_v2  test_v2.zip  training_v2\ttraining_v2.zip\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1FzWMzA1c1j"
   },
   "source": [
    "## Install & import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ONbAsYwBq9bP"
   },
   "outputs": [],
   "source": [
    "!pip install quicksectx git+https://github.com/medspacy/medspacy_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bOTovA88rIrq"
   },
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "from medspacy_io.reader import BratDocReader\n",
    "from medspacy_io.reader import BratDirReader\n",
    "import spacy\n",
    "from pathlib import Path\n",
    "from medspacy_io.vectorizer import Vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gGKInWvJrUPh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1706810622491,
     "user": {
      "displayName": "Jade Broken",
      "userId": "16103365057160619176"
     },
     "user_tz": 420
    },
    "id": "nx6cwF9ZsQaq",
    "outputId": "d27dd542-70bd-4e7c-f112-24133f653882"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dataset files does not include schema configuration, let's create one\n",
    "concepts=['EVIDENCE_OF_PNEUMONIA', 'PNEUMONIA_DOC_NO', 'PNEUMONIA_DOC_YES']\n",
    "lines=['[entities]']+concepts\n",
    "Path('annotation.conf').write_text('\\n'.join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdi6uXEWrwxn"
   },
   "outputs": [],
   "source": [
    "# set up the Brat reader\n",
    "nlp=spacy.load(\"en_core_web_sm\", disable=['ner'])\n",
    "dir_reader = BratDirReader(nlp=nlp, support_overlap=True, recursive=True, schema_file='annotation.conf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7GTpihbUyrRr"
   },
   "outputs": [],
   "source": [
    "# This function will read brat annotation files and convert the snippet annotation into sentence labelled dataframe\n",
    "def convert2df(data_folder):\n",
    "  # read brat annotation into spaCy doc object.\n",
    "  docs = dir_reader.read(txt_dir=data_folder)\n",
    "  # convert snippet label into sentence-level labels and generate pandas dataframe\n",
    "  df = Vectorizer.docs_to_sents_df(docs, track_doc_name=True)\n",
    "  # remove document-level labels\n",
    "  df=df[~df['y'].str.contains('_DOC_')]\n",
    "  return df[['X','y']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IpYIjIwItMW7"
   },
   "outputs": [],
   "source": [
    "train_df=convert2df('training_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T7JmmMO0tW1-"
   },
   "outputs": [],
   "source": [
    "# Let's check the EVIDENCE_OF_PNEUMONIA annotations\n",
    "train_df[train_df['y']!='NEG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fk0j66ztxnJM"
   },
   "outputs": [],
   "source": [
    "# Take a look at https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "# and see what you can configure for this vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(train_df['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PwtcLWSVx4e7"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# now we start to train a svm model\n",
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "model.fit(X, train_df['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B33Acv9U3ufS"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d-QiZLGYyL3c"
   },
   "outputs": [],
   "source": [
    "# let's how it does on training set, this comparison usually is not considered as evaluation.\n",
    "# But it can give us an impression about if the model complexity is sufficient, whether the model is overfitting, etc.\n",
    "predictions = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8aTzdAiZycaF"
   },
   "outputs": [],
   "source": [
    "print(classification_report(train_df['y'], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V0V--RdL4bJH"
   },
   "source": [
    "Now we take a look at test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lPGb0MQ8ygof"
   },
   "outputs": [],
   "source": [
    "test_df=convert2df('test_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4mF6kGEczvxG"
   },
   "outputs": [],
   "source": [
    "# Note: you will have to use \"transform\" here, instead of \"fit_transform\", why?\n",
    "X_test = vectorizer.transform(test_df['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PqptQKa5z2W3"
   },
   "outputs": [],
   "source": [
    "y_test_preds=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iiEdPUJKz5wJ"
   },
   "outputs": [],
   "source": [
    "print(classification_report(test_df['y'], y_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3iu9xvq4tOU"
   },
   "source": [
    "**Compare** the performance above, what the difference tells you?\n",
    "\n",
    "Now we take a closer look to the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "alXPyCAt5W3K"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tVA0Ui7Z0Fmq"
   },
   "outputs": [],
   "source": [
    "test_df['pred']=y_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2yYtzoIr5HQb"
   },
   "outputs": [],
   "source": [
    "test_df[test_df['y']!=test_df['pred']][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPZBFCtM52Fv"
   },
   "source": [
    "## Check a few more errors.\n",
    "What have you found? What's the possible cause of these errors?\n",
    "\n",
    "\n",
    "## Now let's try applying TfIdf\n",
    "Read this page and examples\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "## Exercise:\n",
    "* Implement your solution.\n",
    "* Try at least 3 more tricks that you think would be effective and see if these methods can help improve the performance, e.g. stemming, normalization, etc.\n",
    "* Instead of perform sentence classification, try document classification instead. (Hint: Inside the function \"convert2df\", we filtered out the document level annotations. For this task, you will actually use these labels and disregard 'EVIDENCE_OF_PNEUMONIA')\n",
    "\n",
    "\n",
    "You will be asked to demonstrate and explain your work during the class.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMObAcNuuaOD5zxrmecLzB4",
   "mount_file_id": "1xSZ8EjHXBTVzSzpELDRSqn9k3haTFxYj",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
